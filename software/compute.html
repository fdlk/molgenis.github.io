<!DOCTYPE html><!--[if lt IE 8]><html lang="en" class="ie"><![endif]--><!--[if gt IE 8]><!--><html lang="en"><!--<![endif]--><head><meta charset="utf-8"><title>MOLGENIS - MOLGENIS/compute</title><meta name="description" content="For HPC pipelines on computer clusters"><meta name="author" content="MOLGENIS community"><meta name="handheldfriendly" content="true"><meta name="mobileoptimized" content="320"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta http-equiv="cleartype" content="on"><script src="/res/js/jquery-1.11.3.min.js"> </script><script src="/res/js/bootstrap.min.js"></script><link rel="stylesheet" href="/res/css/prism.css"><link rel="stylesheet" href="/res/css/application.css" type="text/css"><link rel="shortcut icon" href="/favicon.png" type="image/png"><link rel="alternate" type="application/rss+xml" href="/blog/feed.xml" title="undefined"></head><body><header class="molgenis-docs-header"><div role="navigation" class="navbar navbar-fixed-top"><div class="header-container"><div class="navbar-header"><button type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar" class="navbar-toggle collapsed"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a href="/" class="navbar-brand active"><img src="/res/images/wordmark-blue.png" alt="undefined" class="wordmark"/></a></div><div class="collapse navbar-collapse">              <ul class="nav navbar-nav"><li class="active"><a href="/software">TOOLS</a></li><li><a href="/documentation">DOCUMENTATION</a></li><li><a href="/pipelines">PIPELINES</a></li><li><a href="/develop">DEVELOP</a></li><li><a href="/support">SUPPORT</a></li><li><a href="#searchbox" data-toggle="collapse"><i class="glyphicon glyphicon-search"></i></a></li></ul></div></div></div><div id="searchbox" class="collapse"><form role="search" action="/search-results"><input placeholder="Search" name="q" class="form-control"/></form></div><div class="molgenis-docs-titlebar active"><div class="container"> <h1>MOLGENIS/compute</h1><p>For HPC pipelines on computer clusters   </p></div></div></header><div class="molgenis-docs-body"><div class="container"><div class="row"><div role="complementary" class="col-md-3"><nav id="molgenis-docs-sidebar" class="molgenis-docs-sidebar hidden-print hidden-xs hidden-sm"><ul id="molgenis-docs-sidenav" class="nav molgenis-docs-sidenav"></ul></nav><script>$(function() {
    var sideNav = $("#molgenis-docs-sidenav");
    var index = 0;
    $(".row h1").each(function() {
        
        //create id for h1
        var id = (index++) + $(this).text().replace(/\s/gi,"-").replace(/\W/g,"").toLowerCase();
        $(this).prepend("<a name=\""+id+"\"></a>");
        
        //add h1 to list
        var li = $("<li><a href=\"#"+id+"\">"+$(this).text()+"</a></li>")
        sideNav.append(li);
        
        //wrap h1 into section
        var section = $(this).wrap("<section id=\""+id+"\"></section>").parent();
        
        //wrap parts of h1 into one section
        $(this).parent().nextUntil("h1").each(function(){            
            section.append($(this));
        });
        
        //repeat for h2
        if($("h2",$(this).parent()).length > 0) {
            var ul = $("<ul class=\"nav\"></ul>");
            li.append(ul);
            
            $("h2",$(this).parent()).each(function(){
            
                //create id for h2
                var id = (index++) + $(this).text().replace(/\s/gi,"-").replace(/\W/g,"").toLowerCase();
                $(this).prepend("<a name=\""+id+"\"></a>");
        
                //wrap h2 into section
                var section = $(this).wrap("<section id=\""+id+"\"></section>").parent();
        
                ul.append($("<li><a href=\"#"+id+"\">"+$(this).text()+"</a></li>"));
        
                //wrap parts of h2 into one section
                $(this).parent().nextUntil("h2").each(function(){            
                    section.append($(this));
                });
            

            });
        }
    });    
    
    //add "back to top"
    sideNav.append("<li><a href=\"#top\" style=\"font-size:smaller\">Back to top</a></li>");
    var $body   = $(document.body);
    
    //enable the 'active' highlighting using scrollspy plugin
    $('body').scrollspy({
        target: '#molgenis-docs-sidebar'
    });
    $('#molgenis-docs-sidebar').width($('#molgenis-docs-sidebar').parent().width());
    
    //enable affix
    $('#molgenis-docs-sidebar').affix({
        offset: {
            top: $('#molgenis-docs-sidebar').offset().top,
            bottom: $('.molgenis-docs-footer').outerHeight(true) + 10
        }
    });
    
    //resize affix box when window resizes
    $(window).resize(function () {
            $('.molgenis-docs-sidebar').width($('#molgenis-docs-sidebar').parent().width());
        });
    
    $("table").addClass("table table-bordered");
});</script></div><div role="main" class="col-md-9 contents"><h1>MOLGENIS/compute</h1><p><strong>
In this quickstart you will learn to create a workflow, create a workflow run and execute the run.
</strong></p>
<h1>1. Create a workflow</h1><p>We assume you   downloaded and unzipped molgenis compute commandline and are now in the directory you downloaded.</p>
<p>You can generate a template for a new workflow using command:</p>
<pre><code class="language-bash">  sh molgenis_compute.sh --create myfirst_workflow
</code></pre>
<p>This will create a new directory for the workflow:</p>
<pre><code class="language-bash">  cd myfirst_workflow
  ls
</code></pre>
<p>The directory contains a typical Molgenis Compute workflow structure</p>
<pre><code class="language-bash">  /protocols              #folder with bash script &#39;protocols&#39;
  /protocols/step1.sh     #example of a protocol shell script
  /protocols/step2.sh     #example of a protocol shell script
  workflow.csv            #file listing steps and parameter flow
  workflow.defaults.csv   #default parameters for workflow.csv (optional)
  parameters.csv          #parameters you want to run analysis on
  header.ftl              #user extra script header (optional)
  footer.ftl              #user extra script footer (optional)
</code></pre>
<h2>Define workflow</h2><p>You can define a workflow of steps using the workflow.csv file. 
For example:</p>
<pre><code>  step,protocol,dependencies
  step1,protocols/step1.sh,
  step2,protocols/step2.sh,step1
</code></pre><p>This example consists of two steps &#39;step1&#39; and &#39;step2&#39;, where &#39;step2&#39; depends on &#39;step1&#39;. &#39;step1&#39; has its contents in the file protocols/step1.sh and &#39;step2&#39; in the file protocols/step2.sh respectively.</p>
<p>If we want parameter values to flow between steps, we can also map the parameters:</p>
<pre><code>  step,protocol,parameterMapping
  step1,protocols/step1.sh,in=input
  step2,protocols/step2.sh,wf=workflowName;date=creationDate;strings=step1.out;in=input
</code></pre><h2>Define parameters</h2><p>To feed parameter values to your workflow you can also use simple csv files. In this example, one parameter &#39;input&#39; has two values &#39;hello&#39; and &#39;bye&#39;:</p>
<pre><code>  input
  hello
  bye
</code></pre><h2>Define step contents</h2><p>Finally, you need to implement what needs to happen at each step. We therefor define for each step a &#39;protocol&#39;. Protocols are simply bash scripts containing the commands you want to run</p>
<p>For example protocols/step1.sh:</p>
<pre><code class="language-bash">  #string in
  #output out
  echo ${in}_hasBeenInStep1
  out=${in}_hasBeenInStep1
</code></pre>
<p>Given the parameters above, &#39;input&#39; will be substituted with values &#39;hello&#39; or &#39;bye&#39;.
In addition, the contents of &#39;out&#39; will be available to the next step.</p>
<p>Inputs can either be &#39;#string&#39; for variables with a single value or &#39;#list&#39; for variables with multiple values. The outputs are specified with the flag &#39;#output&#39;</p>
<p>In the same way, we can map outputs of one step to the inputs of the next steps. In our example, &#39;strings&#39; in the &#39;step2&#39;, which has protocol step2.ftl</p>
<pre><code class="language-bash">  #string wf
  #string date
  #list strings
  echo &quot;Workflow name: ${wf}&quot;
  echo &quot;Created: ${date}&quot;
  echo &quot;Result of step1.sh:&quot;
  for s in &quot;${strings[@]}&quot;
  do
    echo ${s}
  done
  echo &quot;(FOR TESTING PURPOSES: your runid is ${runid})&quot;
</code></pre>
<p>The example protocols has the following listings:</p>
<p>In our example variables &#39;date&#39; and &#39;wf&#39; are defined in 
an additional parameters file +workflow.defaults.csv+.</p>
<pre><code>  workflowName,creationDate
  myFirstWorkflow,today
</code></pre><p>In this way, the parameters can be divided in several groups and re-used in different workflows. If users do not like to map 
parameters, they should use the same names in protocols and parameters files. This makes parameters a kind of global.</p>
<h1>2. Generate jobs</h1><p>Once you defined your workflow you can generate 1000s of jobs. Just change the parameter values to have different runs. </p>
<pre><code class="language-bash">  sh molgenis_compute.sh --generate --parameters myfirst_workflow/parameters.csv --workflow myfirst_workflow/workflow.csv --defaults myfirst_workflow/workflow.defaults.csv
</code></pre>
<p>or with a short command-line version</p>
<pre><code class="language-bash">  sh molgenis_compute.sh -g -p myfirst_workflow/parameters.csv -w myfirst_workflow/workflow.csv -defaults myfirst_workflow/workflow.defaults.csv
</code></pre>
<p>The directory <code>rundir</code> is created.</p>
<pre><code class="language-bash">  ls rundir/
</code></pre>
<p>It contains a number of files</p>
<pre><code class="language-bash">  doc        
  step1_0.sh    
  step1_1.sh    
  step2_0.sh    
  submit.sh    
  user.env
</code></pre>
<p>.sh are actual scripts generated from the specified workflow. &#39;step1&#39; has two scripts and &#39;step2&#39; has only one, because it treats
outputs from scripts of the &#39;step1&#39; as a list, which is specified in step2.sh by</p>
<pre><code class="language-bash">    #list strings
</code></pre>
<p>user.env contains all actual parameters mappings. In this example:</p>
<pre><code class="language-bash">  #
  ## User parameters
  #
  creationDate[0]=&quot;today&quot;
  creationDate[1]=&quot;today&quot;
  input[0]=&quot;hello&quot;
  input[1]=&quot;bye&quot;
  workflowName[0]=&quot;myFirstWorkflow&quot;
  workflowName[1]=&quot;myFirstWorkflow&quot;
</code></pre>
<p>Parameters, which are known before hand can be connected to the environment file or weaved directly in the protocols (if &#39;weave&#39; flag is set in command-line options). In our example, two shell scripts are generated for 
the &#39;step1&#39;. The weaved version of generated files are shown below.</p>
<p>step1_0.sh:</p>
<pre><code class="language-bash">  #string in
  #output out
  # Let&#39;s do something with string &#39;in&#39;
  echo &quot;hello_hasBeenInStep1&quot;
  out=hello_hasBeenInStep1
</code></pre>
<p>and step1_1.sh</p>
<pre><code class="language-bash">  #string in
  #output out
  # Let&#39;s do something with string &#39;in&#39;
  echo &quot;bye_hasBeenInStep1&quot;
  out=bye_hasBeenInStep1
</code></pre>
<p>The output values of the first steps are not known beforehand, so, &#39;string&#39; cannot be weaved and will stay in the generated for the &#39;step2&#39; script as it was. However, the &#39;wf&#39; and &#39;date&#39; values are weaved.</p>
<p>step2_0.sh:</p>
<pre><code class="language-bash">  #string wf
  #string date
  #list strings
  echo &quot;Workflow name: myFirstWorkflow&quot;
  echo &quot;Created: today&quot;
  echo &quot;Result of step1.sh:&quot;
  for s in &quot;${strings[@]}&quot;
  do
      echo ${s}
  done
</code></pre>
<p>If values can be known, the script will have the following content </p>
<p>step2_0.sh with all known values:</p>
<pre><code class="language-bash">  #string wf
  #string date
  #list strings
  echo &quot;Workflow name: myFirstWorkflow&quot;
  echo &quot;Created: today&quot;
  echo &quot;Result of step1.sh:&quot;
  for s in &quot;hello&quot; &quot;bye&quot;
  do
      echo ${s}
  done
</code></pre>
<p>If &#39;weaved&#39; flag is not set, +step1_0.sh+ file, for example looks as follows:</p>
<pre><code class="language-bash">  # Connect parameters to environment
  input=&quot;bye&quot;
  #string input
  # Let&#39;s do something with string &#39;in&#39;
  echo &quot;${input}_hasBeenInStep1&quot;
  out=${input}_hasBeenInStep1
</code></pre>
<p>In this way, users can choose how generated files look like.
In the current implementation, values are first taken from parameter files. If they are not present, then compute looks,
if these values can be known at run-time, by analysing all previous steps of the protocol, where values are unknown.
If values cannot be known at run-time, compute will give a generation error. </p>
<h1>3. Execute workflow</h1><h2>Execute locally</h2><p>Compute can execute the jobs locally with command:</p>
<pre><code class="language-bash">  sh molgenis_compute.sh --run
  ls rundir/
</code></pre>
<p>Now, rundir contains more files</p>
<pre><code class="language-bash">  doc                
  step1_0.sh            
  step1_1.sh            
  step2_0.sh
  submit.sh
  step1_0.sh.started        
  step1_1.sh.started        
  step2_0.sh.started
  step1_0.env            
  step1_1.env            
  step2_0.env    
  step1_0.sh.finished        
  step1_1.sh.finished        
  step2_0.sh.finished
  molgenis.bookkeeping.log        
  user.env
</code></pre>
<p>.started and .finished files are created, when certain jobs are started and finished respectively. </p>
<p>In our example, &#39;strings&#39; variable from &#39;step2&#39; requires run-time values produced in &#39;step1&#39;. These values are taken from step1_X.env files. For example:</p>
<p>step1_0.env:</p>
<pre><code class="language-bash">  step1__has__out[0]=hello_hasBeenInStep1
</code></pre>
<p>In the workflow.csv file, it is specified with a simple &#39;.&#39; </p>
<pre><code class="language-bash">  strings=step1.out
</code></pre>
<p>and substituted with &#39;<strong>has</strong>&#39; in generated script files.</p><center><br><i>See something that could be better? <a href="https://github.com/molgenis/molgenis.org/tree/master/public/software/compute.md">Edit this page at Github</a></i><br></center></div></div></div></div><footer class="molgenis-docs-footer"><p>MOLGENIS and these docs are maintained by the <a href="http://www.gccgroningen.nl/about-us/people-at-the-gcc/">MOLGENIS team and collaborators</a>. <br/> Documentation source code released under the <a href="/LICENSE-MIT">MIT License</a>, documentation contents under <a href="/LICENSE-CC">CC BY 3.0</a>, and MOLGENIS software code under the <a href="/LICENSE-LGPLv3">LGPLv3 License</a>.<ul class="text-muted"><li>Version 2.0.0</li><li>·</li><li><a href="https://github.com/molgenis/molgenis">MOLGENIS Github</a></li><li>·</li><li><a href="http://github.com/molgenis/molgenis/issues">MOLGENIS Issues</a></li><li>·</li><li><a href="https://github.com/molgenis/molgenis.org/tree/master/public">Docs Github    </a></li><li>·</li><li><a href="http://github.com/molgenis/molgenis.org/issues">Docs Issues</a></li><li>·</li><li><a href="https://github.com/molgenis/molgenis/releases">Releases</a></li></ul></p></footer><script src="/res/js/prism.js"></script></body></html>