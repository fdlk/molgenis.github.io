<!DOCTYPE html><!--[if lt IE 8]><html lang="en" class="ie"><![endif]--><!--[if gt IE 8]><!--><html lang="en"><!--<![endif]--><head><meta charset="utf-8"><title>MOLGENIS - Protocols</title><meta name="description" content="Steps explained"><meta name="author" content="MOLGENIS community"><meta name="handheldfriendly" content="true"><meta name="mobileoptimized" content="320"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta http-equiv="cleartype" content="on"><script src="/res/js/jquery-1.11.3.min.js"> </script><script src="/res/js/bootstrap.min.js"></script><link rel="stylesheet" href="/res/css/prism.css"><link rel="stylesheet" href="/res/css/application.css" type="text/css"><link rel="shortcut icon" href="/favicon.png" type="image/png"><link rel="alternate" type="application/rss+xml" href="/blog/feed.xml" title="undefined"></head><body><header class="molgenis-docs-header"><div role="navigation" class="navbar navbar-fixed-top"><div class="header-container"><div class="navbar-header"><button type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar" class="navbar-toggle collapsed"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a href="/" class="navbar-brand active"><img src="/res/images/wordmark-blue.png" alt="undefined" class="wordmark"/></a></div><div class="collapse navbar-collapse">              <ul class="nav navbar-nav"><li><a href="/software">TOOLS</a></li><li><a href="/documentation">DOCUMENTATION</a></li><li class="active"><a href="/pipelines">PIPELINES</a></li><li><a href="/develop">DEVELOP</a></li><li><a href="/support">SUPPORT</a></li><li><a href="/gcc">GCC wiki</a></li><li><a href="#searchbox" data-toggle="collapse"><i class="glyphicon glyphicon-search"></i></a></li></ul></div></div></div><div id="searchbox" class="collapse"><form role="search" action="/search-results"><input placeholder="Search" name="q" class="form-control"/></form></div><div class="molgenis-docs-titlebar active"><div class="container"> <h1>Protocols</h1><p>Steps explained   </p></div></div></header><div class="molgenis-docs-body"><div class="container"><div class="row"><div role="complementary" class="col-md-3"><nav id="molgenis-docs-sidebar" class="molgenis-docs-sidebar hidden-print hidden-xs hidden-sm"><ul id="molgenis-docs-sidenav" class="nav molgenis-docs-sidenav"></ul></nav><script>$(function() {
    var sideNav = $("#molgenis-docs-sidenav");
    var index = 0;
    $(".row h1").each(function() {
        
        //create id for h1
        var id = (index++) + $(this).text().replace(/\s/gi,"-").replace(/\W/g,"").toLowerCase();
        $(this).prepend("<a name=\""+id+"\"></a>");
        
        //add h1 to list
        var li = $("<li><a href=\"#"+id+"\">"+$(this).text()+"</a></li>")
        sideNav.append(li);
        
        //wrap h1 into section
        var section = $(this).wrap("<section id=\""+id+"\"></section>").parent();
        
        //wrap parts of h1 into one section
        $(this).parent().nextUntil("h1").each(function(){            
            section.append($(this));
        });
        
        //repeat for h2
        if($("h2",$(this).parent()).length > 0) {
            var ul = $("<ul class=\"nav\"></ul>");
            li.append(ul);
            
            $("h2",$(this).parent()).each(function(){
            
                //create id for h2
                var id = (index++) + $(this).text().replace(/\s/gi,"-").replace(/\W/g,"").toLowerCase();
                $(this).prepend("<a name=\""+id+"\"></a>");
        
                //wrap h2 into section
                var section = $(this).wrap("<section id=\""+id+"\"></section>").parent();
        
                ul.append($("<li><a href=\"#"+id+"\">"+$(this).text()+"</a></li>"));
        
                //wrap parts of h2 into one section
                $(this).parent().nextUntil("h2").each(function(){            
                    section.append($(this));
                });
            

            });
        }
    });    
    
    //add "back to top"
    sideNav.append("<li><a href=\"#top\" style=\"font-size:smaller\">Back to top</a></li>");
    var $body   = $(document.body);
    
    //enable the 'active' highlighting using scrollspy plugin
    $('body').scrollspy({
        target: '#molgenis-docs-sidebar'
    });
    $('#molgenis-docs-sidebar').width($('#molgenis-docs-sidebar').parent().width());
    
    //enable affix
    $('#molgenis-docs-sidebar').affix({
        offset: {
            top: $('#molgenis-docs-sidebar').offset().top,
            bottom: $('.molgenis-docs-footer').outerHeight(true) + 10
        }
    });
    
    //resize affix box when window resizes
    $(window).resize(function () {
            $('.molgenis-docs-sidebar').width($('#molgenis-docs-sidebar').parent().width());
        });
    
    $("table").addClass("table table-bordered");
});</script></div><div role="main" class="col-md-9 contents"><h3>Step 1: Calculate QC metrics on raw data</h3><p>In this step, Fastqc, quality control (QC) metrics are calculated for the raw sequencing data. This is done using the tool FastQC. This tool will run a series of tests on the input file. The output is a text file containing the output data which is used to create a summary in the form of several HTML pages with graphs for each test. Both the text file and the HTML document provide a flag for each test: pass, warning or fail. This flag is based on criteria set by the makers of this tool. Warnings or even failures do not necessarily mean that there is a problem with the data, only that it is unusual compared to the used criteria. It is possible that the biological nature of the sample means that this particular bias is to be expected.</p>
<p>Toolname: FastQC</p>
<p>Scriptname: Fastqc</p>
<p>Input: FastQ files (${filePrefix}<em>${lane}</em>${barcode}.fq.gz)</p>
<p>Output: ${filePrefix}.fastqc.zip archive containing amongst others the HTML document and the text file</p>
<pre><code>fastqc \
    fastq1.gz \
    fastq2.gz \
    -o outputDirectory
</code></pre><h3>Step 2: Read alignment against reference sequence</h3><p>In this step, the Hisat Aligner is used to align the (mostly paired end) sequencing data to the reference genome. The output is a SAM file.</p>
<p>Scriptname: HisatAlignment</p>
<p>Input: raw sequence file in the form of a gzipped fastq file (${filePrefix}.fq.gz)
Output: SAM formatted file (${filePrefix}.sam)</p>
<p>Toolname: Hisat</p>
<pre><code>hisat -x ${hisatIndex} \
    ${input} \
    -p 8 \
    --rg-id ${externalSampleID} \
    --rg PL:illumina \
    --rg PU:${sequencer}_${flowcell}_${run}_${lane}_${barcode} \
    --rg LB:${sequencer}_${flowcell}_${run}_${lane}_${barcode} \
    --rg SM:${externalSampleID} \
    -S ${tmpAlignedSam} &gt; ${intermediateDir}/${externalSampleID}_L${lane}.hisat.log 2&gt;&amp;1
</code></pre><h3>Step 3: Add Or Replace Readgroup</h3><p>This step adds readgroup information to the reads in a bamfile. This additional meta data inproves the mark duplicate step by making it possible the identify different sequence runs for indiviual samples, but also various technical features that are associated with artifacts.</p>
<p>Toolname: Picard AddOrReplaceReadGroups</p>
<p>ToolVersion: 1.130-Java-1.7.0_80</p>
<p>Input: BAM files from step 2 ${filePrefix}_${barcode}.sorted.bam)</p>
<p>Output: merged BAM file ${filePrefix}_${barcode}.sorted.rg.bam)</p>
<p>java -Xmx6g -XX:ParallelGCThreads=8 -jar ${EBROOTPICARD}/${picardJar} AddOrReplaceReadGroups \
    INPUT=${sortedBam} \
    OUTPUT=${tmpAddOrReplaceGroupsBam} \
    SORT<em>ORDER=coordinate \
    RGID=${externalSampleID} \
    RGLB=${sequencer}</em>${flowcell}<em>${run}</em>${lane}<em>${barcode} \
    RGPL=ILLUMINA \
    RGPU=${sequencer}</em>${flowcell}<em>${run}</em>${lane}_${barcode} \
    RGSM=${externalSampleID} \
    RGDT=$(date --rfc-3339=date) \
    CREATE_INDEX=true \
    MAX_RECORDS_IN_RAM=4000000 \
     TMP_DIR=${tempDir}</p>
<pre><code>### Step 4: Merge BAM and build index

To improve the coverage of sequence alignments, a sample can be sequenced on multiple lanes and/or flowcells. If this is the case for the sample(s) being analyzed, this step merges all BAM files of one sample and indexes this new file. If there is just one BAM file for a sample, nothing happens.

Toolname: Picard mergeBam

ToolVersion: 1.130-Java-1.7.0_80

Input: BAM files from step 2 ${filePrefix}_${barcode}.sorted.bam)

Output: merged BAM file (${sample}. sorted .merged.bam)

java -XX:ParallelGCThreads=4 -jar -Xmx6g ${EBROOTPICARD}/${picardJar} ${mergeSamFilesJar} \
    ${INPUTS[@]} \
    SORT_ORDER=coordinate \
    CREATE_INDEX=true \
    USE_THREADING=true \
    TMP_DIR=${tempDir} \
    MAX_RECORDS_IN_RAM=6000000 \
    VALIDATION_STRINGENCY=LENIENT \
    OUTPUT=${tmpSampleMergedBam}
</code></pre><h3>Step 5: Mark duplicates + creating dedup metrics</h3><p>In this step, the BAM file is examined to locate duplicate reads, using Picard MarkDuplicates. A mapped read is considered to be duplicate if the start and end base of two or more reads are located at the same chromosomal position in comparison to the reference genome. For paired-end data the start and end locations for both ends need to be the same to be called duplicate. One read pair of these duplicates is kept, the remaining ones are flagged as being duplicate.</p>
<p>Toolname: Picard MarkDuplicates </p>
<p>Scriptname: MarkDuplicates</p>
<p>Input: Merged BAM file from generated in step 3 (${sample}.sorted.merged.bam)</p>
<p>Output: BAM file with duplicates flagged (${sample}.sorted.merged dedup.bam)
BAM index file (${sample}.dedup.bam.bai)
Dedup metrics file (${sample}.merged.dedup.metrics)</p>
<p>java -XX:ParallelGCThreads=4 -jar -Xmx6g ${EBROOTPICARD}/${picardJar} MarkDuplicates \
    I=${sampleMergedBam} \
    O=${tmpSampleMergedDedupBam} \
    CREATE_INDEX=true \
    VALIDATION_STRINGENCY=LENIENT \
    M=${dupStatMetrics} AS=true</p>
<pre><code>### Step 6: Calculate alignment QC metrics
In this step, QC metrics are calculated for the alignments created in the previous steps. This is done using several QC related tools:
•    ${PICARD}/CollectRnaSeqMetrics
•    ${GCC}/gentrap_graph_seqgc (GC bias plot) 
•    ${SAMTOOLS}/flagstat 
•    ${PICARD}/MarkDuplicates
•    ${PICARD}/CollectInsertSizeMetrics (only paired end)

Toolname: several Picard or Samtools QC tools
ScriptVersions: Samtools/1.2-goolf-1.7.20, picard-tools/1.130-Java-1.7.0_80
Input: BAM file generated in step 4
Output: collectrnaseqmetrics, alignmentmetrics, gcbiasplots, insertsizemetrics, dedupmetrics, (text files and matching PDF files)

These metrics are later used to create tables and graphs (step 9). The Picard tools also output a PDF version of the data themselves, containing graphs.



### Step 7: HTSeq Count, Gene expression quantification
Before gene expression quantification SAMtools was used to sort the aligned reads by name. 
The gene level quantification was performed by HTSeq-0.6.1p1 using --mode=union --stranded=no|yes and, Ensembl version 75 was used as gene annotation database.

toolName: HTSeq Count 
toolVersion: HTSeq/0.6.1p1, Samtools/1.2-goolf-1.7.20
Input: BAM file
Output: Textfile with gene level quantification per sample.

samtools \
    view -h \
    ${sampleMergedBam}.nameSorted.bam | \
    $EBROOTHTSEQ/scripts/htseq-count \
    -m union \
    -s ${STRANDED} \
    - \
    ${annotationGtf} | \
    head -n -5 \
    &gt; ${tmpSampleHTseqExpressionText}
</code></pre><h3>Step 8a: GATK: SplitAndTrim</h3><p>In this step the data is pre-processed for variantcalling using GATK SplitNCigarReads,  which splits reads into exon segments (getting rid of Ns but maintaining grouping information) and hard-clip any sequences overhanging into the intronic regions. </p>
<p>Toolname: GATK SplitNCigarReads
Scriptname: SplitAndTrim
Input: merged BAM files
Output: BAM file (${sample}.sorted.merged.dedup.splitAndTrim.bam)</p>
<p>java -Xmx9g -XX:ParallelGCThreads=8 -Djava.io.tmpdir=${tmpTmpDataDir} -jar ${EBROOTGATK}/GenomeAnalysisTK.jar \
  -T SplitNCigarReads \
  -R ${indexFile} \
  -I ${sampleMergedDedupBam} \
  -o ${tmpsplitAndTrimBam} \
  -rf ReassignOneMappingQuality \
  -RMQF 255 \
  -RMQT 60 \
  -U ALLOW_N_CIGAR_READS</p>
<pre><code>
### Step 8b: IndelRealignment
The local realignment process is designed to consume one or more BAM files and to locally realign reads such that the number of mismatching bases is minimized across all the reads.
Toolname GATK SplitAndTrim
Input: BAM file from step 8a
Output: BAM file (${sample}.sorted.merged.dedup.splitAndTrim. realigned.bam)

java -Xmx8g -XX:ParallelGCThreads=8 -Djava.io.tmpdir=${tmpTmpDataDir} -jar $EBROOTGATK/GenomeAnalysisTK.jar \
    -T IndelRealigner \
    -R ${indexFile} \
    -I ${splitAndTrimBam} \
    -o ${tmpIndelRealignedBam} \
    -targetIntervals ${indelRealignmentTargets} \
    -known ${oneKgPhase1IndelsVcf} \
    -known ${goldStandardVcf} \
    -U ALLOW_N_CIGAR_READS \
    --consensusDeterminationModel KNOWNS_ONLY \
    --LODThresholdForCleaning 0.4


### Step 8c: BQSR
In this step BQSR is performed. This is a data pre-processing step that detects systematic errors made by the sequencer when it estimates the quality score of each base call.
Toolname GATK BQSR
Input: BAM file from step 8b
Output: BAM file (${sample}.sorted.merged.dedup.splitAndTrim. realigned.bqsr.bam)

java -Xmx14g -XX:ParallelGCThreads=8 -Djava.io.tmpdir=${tmpTmpDataDir} -jar $EBROOTGATK/GenomeAnalysisTK.jar \
    -T BaseRecalibrator\
    -R ${indexFile} \
    -I ${IndelRealignedBam} \
    -o ${bqsrBeforeGrp} \
    -knownSites ${dbsnpVcf} \
    -knownSites ${goldStandardVcf} \
    -knownSites ${oneKgPhase1IndelsVcf} \
    -nct 2

java -Xmx14g -XX:ParallelGCThreads=8 -Djava.io.tmpdir=${tmpTmpDataDir} -jar $EBROOTGATK/GenomeAnalysisTK.jar \
    -T PrintReads \
    -R ${indexFile} \
    -I ${IndelRealignedBam} \
    -o ${tmpBqsrBam} \
    -BQSR ${bqsrBeforeGrp} \
    -nct 2
</code></pre><h3>Step 9a: HaplotypeCallerGvcf (VariantCalling)</h3><p>The GATK HaplotypeCaller estimates the most likely genotypes and allele frequencies in a alignment using a Bayesian likelihood model for every position of the genome regardless of whether a variant was detected at that site or not. This information can later be used in the project based genotyping step.</p>
<p>Toolname: GATK HaplotypeCallerGvcf
Scriptname: HaplotypeCallerGvcf
Input: (${sample.sorted.merged.dedup.splitAndTrim.bam 
Output: gVCF file (${sample}.${batchBed}.variant.calls.g.vcf)</p>
<p>java -Xmx10g -XX:ParallelGCThreads=8 -Djava.io.tmpdir=${tmpTmpDataDir} -jar ${EBROOTGATK}/GenomeAnalysisTK.jar \
    -T HaplotypeCaller \
    -R ${indexFile} \
    ${inputs[@]} \
    --dbsnp ${dbsnpVcf}\
    -dontUseSoftClippedBases \
    -stand_call_conf 10.0 \
    -stand_emit_conf 20.0 \
    -o ${tmpGatkHaplotypeCallerGvcf} \
    -variant_index_type LINEAR \
    -variant_index_parameter 128000 \
    --emitRefConfidence GVCF</p>
<h3>Step 9b: Combine variants</h3><p>When there 200 or more samples the gVCF files should be combined into batches of equal size. (NB: These batches are different then the ${batchBed}.)
The batches will be calculated and created in this step. If there are less then 200, this step will automatically be skipped.</p>
<p>Toolname: GATK CombineGVCFs
Scriptname: VariantGVCFCombine
Input: gVCF file (from step 9a)
Output: Multiple combined gVCF files ${project}.${batchBed}.variant.calls.combined.g.vcf{batch}</p>
<p>java -Xmx30g -XX:ParallelGCThreads=2 -Djava.io.tmpdir=${tmpTmpDataDir} -jar \
    ${EBROOTGATK}/GenomeAnalysisTK.jar \
    -T CombineGVCFs \
    -R ${indexFile} \
    -L ${indexChrIntervalList} \
    -o ${tmpProjectBatchCombinedVariantCalls}.${b} \
    ${ALLGVCFs[@]}</p>
<h3>Step 9c: Genotype variants</h3><p>In this step there will be a joint analysis over all the samples in the project. This leads to a posterior probability of a variant allele at a site. SNPs and small Indels are written to a VCF file, along with information such as genotype quality, allele frequency, strand bias and read depth for that SNP/Indel.</p>
<p>Toolname: GATK GenotypeGVCFs
Scriptname: VariantGVCFGenotype
Input: gVCF files from step 9a or combined gVCF files from step 9b
Output: VCF file for all the samples in the project: ${project}.${batchBed}.variant.calls.genotyped.vcf</p>
<p>java -Xmx16g -XX:ParallelGCThreads=2 -Djava.io.tmpdir=${tmpTmpDataDir} -jar ${EBROOTGATK}/GenomeAnalysisTK.jar \
    -T GenotypeGVCFs \
    -R ${indexFile} \
     --dbsnp ${dbsnpVcf}\
    -o ${tmpProjectBatchGenotypedVariantCalls} \
    ${ALLGVCFs[@]} \
    -stand_call_conf 10.0 \
    -stand_emit_conf 20.0</p>
<h3>Step 10: MakeExpressionTable</h3><p>In this step, gene level quantification files per sample, created in step 6 are merged into one table, using a inhouse developt script ProcessReadCounts.</p>
<p>Scriptname: MakeExpressionTable
Input: textfile with gene level quantification per sample.
Output: gene level quantification table with all samples in the project.</p>
<p>java -Xmx1g -XX:ParallelGCThreads=1 -Djava.io.tmpdir=${tmpTmpDataDir} -jar ${EBROOTNGSMINUTILS}/${processReadCountsJar} \
    --mode makeExpressionTable \
    --fileList ${intermediateDir}/fileList.txt \
    --annot ${geneAnnotationTxt} \
    --out ${tmpProjectHTseqExpressionTable}</p>
<h3>Step 11: Generate quality control report</h3><p>This step is to collect the statistics and metrics from step 3. Tables and graphs merged into a HTML and PDF Reports using KnitR. QC reports are then written to a quality control (QC) directory. </p>
<p>Scriptname: QC_report
Input: QC statistics and metrics.
Output: QC report (.QCReport.pdf)</p>
<h3>Step 12: Kallisto</h3><p>In this step kallisto is for quantifying abundances of transcripts from RNA-Seq data, or more generally of target sequences using high-throughput sequencing reads. </p>
<p>Scriptname: Kallisto
Input: raw sequence file in the form of a gzipped fastq file (.fq.gz)
Output: results of the main quantification, i.e. the abundance estimate using Kallisto on the data is in the abundance.txt</p>
<p>kallisto quant \
    -i ${kallistoIndex} \
    -o ${tmpIntermediateDir}/${uniqueID} \
    ${peEnd1BarcodeFqGz} ${peEnd2BarcodeFqGz}</p>
<h3>Step 13: Prepare data to ship to the customer</h3><p>In this last step the final results of the inhouse sequence analysis pipeline are gathered and prepared to be shipped to the customer. The pipeline tools and scripts write intermediate results to a temporary directory. From these, a selection is copied to a results directory. This directory has five subdirectories:</p>
<ul>
<li>alignment: merged BAM file with index</li>
<li>expression: textfiles with gene level quantification per sample, and per project</li>
<li>fastqc: FastQC output </li>
<li>images: QC images</li>
<li>variants: VCF file with calling SNPs and indels.</li>
<li>rawdata: raw sequence file in the form of a gzipped fastq file (.fq.gz)</li>
</ul>
<p>Additionally, the results directory contains the final QC report, a README.txt with used pipeline description and toolversions, and the samplesheet which was the basis for this analysis and a zipped archive with the data that will be shipped to the client. The archive is accompanied by an md5 sum.</p><center><br><i>See something that could be better? <a href="https://github.com/molgenis/molgenis.org/tree/master/public/pipelines/rna-protocols.md">Edit this page at Github</a></i><br></center></div></div></div></div><footer class="molgenis-docs-footer"><p>MOLGENIS and these docs are maintained by the <a href="http://www.gccgroningen.nl/about-us/people-at-the-gcc/">MOLGENIS team and collaborators</a>. <br/> Documentation source code released under the <a href="/LICENSE-MIT">MIT License</a>, documentation contents under <a href="/LICENSE-CC">CC BY 3.0</a>, and MOLGENIS software code under the <a href="/LICENSE-LGPLv3">LGPLv3 License</a>.<ul class="text-muted"><li>Version 2.0.0</li><li>·</li><li><a href="https://github.com/molgenis/molgenis">MOLGENIS Github</a></li><li>·</li><li><a href="http://github.com/molgenis/molgenis/issues">MOLGENIS Issues</a></li><li>·</li><li><a href="https://github.com/molgenis/molgenis.org/tree/master/public">Docs Github    </a></li><li>·</li><li><a href="http://github.com/molgenis/molgenis.org/issues">Docs Issues</a></li><li>·</li><li><a href="https://github.com/molgenis/molgenis/releases">Releases</a></li></ul></p></footer><script src="/res/js/prism.js"></script></body></html>